{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf95383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob as glob\n",
    "import cv2\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "from PIL import ImageFile\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "sys.path.append(\"..\")\n",
    "CWD_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dda5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9e5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v2_german'\n",
    "#MODEL_NAME = 'ssd_mobilenet_v1'\n",
    "#MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "#MODEL_NAME = 'ssd_inception_v2'\n",
    "#MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "#MODEL_NAME = 'faster_rcnn_resnet_101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7836b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join('model', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'weights','saved_model')\n",
    "#PATH_TO_CKPT = os.path.join(MODEL_PATH,'saved_model')\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('new_stop_sign_data', 'stop_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65327bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH_TO_CKPT : model/ssd_mobilenet_v2_german/weights/saved_model\n",
      "PATH_TO_LABELS : new_stop_sign_data/stop_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "print('PATH_TO_CKPT :', PATH_TO_CKPT)\n",
    "print('PATH_TO_LABELS :', PATH_TO_LABELS)\n",
    "tf.keras.backend.clear_session()\n",
    "detect_fn = tf.saved_model.load(PATH_TO_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fcc3251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"stop\"\n",
      "  id: 1\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_20\"\n",
      "  id: 2\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_30\"\n",
      "  id: 3\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_50\"\n",
      "  id: 4\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_60\"\n",
      "  id: 5\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_70\"\n",
      "  id: 6\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_80\"\n",
      "  id: 7\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_100\"\n",
      "  id: 8\n",
      "}\n",
      "item {\n",
      "  name: \"speed_limit_120\"\n",
      "  id: 9\n",
      "}\n",
      "\n",
      "[{'id': 1, 'name': 'stop'}, {'id': 2, 'name': 'speed_limit_20'}, {'id': 3, 'name': 'speed_limit_30'}, {'id': 4, 'name': 'speed_limit_50'}, {'id': 5, 'name': 'speed_limit_60'}, {'id': 6, 'name': 'speed_limit_70'}, {'id': 7, 'name': 'speed_limit_80'}, {'id': 8, 'name': 'speed_limit_100'}, {'id': 9, 'name': 'speed_limit_120'}]\n",
      "{1: {'id': 1, 'name': 'stop'}, 2: {'id': 2, 'name': 'speed_limit_20'}, 3: {'id': 3, 'name': 'speed_limit_30'}, 4: {'id': 4, 'name': 'speed_limit_50'}, 5: {'id': 5, 'name': 'speed_limit_60'}, 6: {'id': 6, 'name': 'speed_limit_70'}, 7: {'id': 7, 'name': 'speed_limit_80'}, 8: {'id': 8, 'name': 'speed_limit_100'}, 9: {'id': 9, 'name': 'speed_limit_120'}}\n"
     ]
    }
   ],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "print(label_map)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "print(categories)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2005183",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = 'new_stop_sign_data/images/test'\n",
    "image_name=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2f5b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, f) for f in listdir(PATH_TO_TEST_IMAGES_DIR) if isfile(os.path.join(PATH_TO_TEST_IMAGES_DIR, f))]\n",
    "TEST_IMAGE_PATHS = sorted(TEST_IMAGE_PATHS)\n",
    "TEST_IMAGE_PATHS = natsorted(TEST_IMAGE_PATHS)\n",
    "#print('TEST_IMAGE_PATHS :',TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa33940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00056.jpg', '00125.jpg', '00134.jpg', '00167.jpg', '00174.jpg', '00181.jpg', '00182.jpg', '00192.jpg', '00223.jpg', '00259.jpg', '00260.jpg', '00285.jpg', '00300.jpg', '00303.jpg', '00316.jpg', '00322.jpg', '00334.jpg', '00348.jpg', '00369.jpg', '00377.jpg', '00405.jpg', '00418.jpg', '00439.jpg', '00441.jpg', '00444.jpg', '00456.jpg', '00457.jpg', '00459.jpg', '00477.jpg', '00480.jpg', '00496.jpg', '00512.jpg', '00513.jpg', '00518.jpg', '00519.jpg', '00524.jpg', '00528.jpg', '00605.jpg', '00609.jpg', '00613.jpg', '00632.jpg', '00651.jpg', '00661.jpg', '00667.jpg', '00670.jpg', '00674.jpg', '00680.jpg', '00688.jpg', '00690.jpg', '00699.jpg', '00701.jpg', '00706.jpg', '00707.jpg', '00716.jpg', '00729.jpg', '00730.jpg', '00734.jpg', '00740.jpg', '00758.jpg', '00789.jpg', '00806.jpg', '00809.jpg', '00829.jpg', '00834.jpg', '00839.jpg', '00849.jpg', '00850.jpg', '00854.jpg', '00860.jpg', '00881.jpg', '00884.jpg', '00891.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_name=[f for f in listdir(PATH_TO_TEST_IMAGES_DIR) if isfile(os.path.join(PATH_TO_TEST_IMAGES_DIR, f))]\n",
    "image_name = sorted(image_name)\n",
    "image_name = natsorted(image_name)\n",
    "print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36deadbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_stop_sign_data/images/test/00480.jpg\n",
      "new_stop_sign_data/images/test/00441.jpg\n",
      "new_stop_sign_data/images/test/00891.jpg\n",
      "new_stop_sign_data/images/test/00456.jpg\n",
      "new_stop_sign_data/images/test/00300.jpg\n",
      "new_stop_sign_data/images/test/00734.jpg\n",
      "new_stop_sign_data/images/test/00405.jpg\n",
      "new_stop_sign_data/images/test/00740.jpg\n",
      "new_stop_sign_data/images/test/00519.jpg\n",
      "new_stop_sign_data/images/test/00834.jpg\n",
      "new_stop_sign_data/images/test/00609.jpg\n",
      "new_stop_sign_data/images/test/00806.jpg\n",
      "new_stop_sign_data/images/test/00670.jpg\n",
      "new_stop_sign_data/images/test/00661.jpg\n",
      "new_stop_sign_data/images/test/00860.jpg\n",
      "new_stop_sign_data/images/test/00056.jpg\n",
      "new_stop_sign_data/images/test/00418.jpg\n",
      "new_stop_sign_data/images/test/00674.jpg\n",
      "new_stop_sign_data/images/test/00758.jpg\n",
      "new_stop_sign_data/images/test/00706.jpg\n",
      "new_stop_sign_data/images/test/00192.jpg\n",
      "new_stop_sign_data/images/test/00690.jpg\n",
      "new_stop_sign_data/images/test/00316.jpg\n",
      "new_stop_sign_data/images/test/00528.jpg\n",
      "new_stop_sign_data/images/test/00285.jpg\n",
      "new_stop_sign_data/images/test/00260.jpg\n",
      "new_stop_sign_data/images/test/00854.jpg\n",
      "new_stop_sign_data/images/test/00513.jpg\n",
      "new_stop_sign_data/images/test/00716.jpg\n",
      "new_stop_sign_data/images/test/00667.jpg\n",
      "new_stop_sign_data/images/test/00730.jpg\n",
      "new_stop_sign_data/images/test/00174.jpg\n",
      "new_stop_sign_data/images/test/00518.jpg\n",
      "new_stop_sign_data/images/test/00707.jpg\n",
      "new_stop_sign_data/images/test/00849.jpg\n",
      "new_stop_sign_data/images/test/00789.jpg\n",
      "new_stop_sign_data/images/test/00496.jpg\n",
      "new_stop_sign_data/images/test/00223.jpg\n",
      "new_stop_sign_data/images/test/00477.jpg\n",
      "new_stop_sign_data/images/test/00377.jpg\n",
      "new_stop_sign_data/images/test/00439.jpg\n",
      "new_stop_sign_data/images/test/00524.jpg\n",
      "new_stop_sign_data/images/test/00322.jpg\n",
      "new_stop_sign_data/images/test/00688.jpg\n",
      "new_stop_sign_data/images/test/00651.jpg\n",
      "new_stop_sign_data/images/test/00259.jpg\n",
      "new_stop_sign_data/images/test/00881.jpg\n",
      "new_stop_sign_data/images/test/00457.jpg\n",
      "new_stop_sign_data/images/test/00459.jpg\n",
      "new_stop_sign_data/images/test/00809.jpg\n",
      "new_stop_sign_data/images/test/00680.jpg\n",
      "new_stop_sign_data/images/test/00632.jpg\n",
      "new_stop_sign_data/images/test/00348.jpg\n",
      "new_stop_sign_data/images/test/00444.jpg\n",
      "new_stop_sign_data/images/test/00512.jpg\n",
      "new_stop_sign_data/images/test/00369.jpg\n",
      "new_stop_sign_data/images/test/00701.jpg\n",
      "new_stop_sign_data/images/test/00699.jpg\n",
      "new_stop_sign_data/images/test/00182.jpg\n",
      "new_stop_sign_data/images/test/00829.jpg\n",
      "new_stop_sign_data/images/test/00334.jpg\n",
      "new_stop_sign_data/images/test/00181.jpg\n",
      "new_stop_sign_data/images/test/00125.jpg\n",
      "new_stop_sign_data/images/test/00884.jpg\n",
      "new_stop_sign_data/images/test/00167.jpg\n",
      "new_stop_sign_data/images/test/00605.jpg\n",
      "new_stop_sign_data/images/test/00303.jpg\n",
      "new_stop_sign_data/images/test/00839.jpg\n",
      "new_stop_sign_data/images/test/00613.jpg\n",
      "new_stop_sign_data/images/test/00850.jpg\n",
      "new_stop_sign_data/images/test/00729.jpg\n",
      "new_stop_sign_data/images/test/00134.jpg\n"
     ]
    }
   ],
   "source": [
    "#def DetectImagesFromFolder(detector, images_dir, save_output=False, output_dir='output/'):\n",
    "\n",
    "for file in os.scandir(PATH_TO_TEST_IMAGES_DIR):\n",
    "    if file.is_file() and file.name.endswith(('.jpg', '.jpeg', '.png')) :\n",
    "        image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, file.name)\n",
    "        #class_id = 1\n",
    "        print(image_path)\n",
    "        img = cv2.imread(image_path)\n",
    "        image_np1 = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        #image_np1 = np.expand_dims(image_np1, axis=0)\n",
    "        #Threshold = 0.5\n",
    "        #print('img : ', img)\n",
    "        #det_boxes = DetectFromImage(img)\n",
    "        #img = detector.DisplayDetections(img, det_boxes)\n",
    "        #img_out = os.path.join(output_dir, file.name)\n",
    "        #cv2.imwrite(img_out, img)\n",
    "        #im_height, im_width, _ = img.shape\n",
    "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "        #input_tensor = np.array(img.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "        input_tensor = np.expand_dims(img, 0)\n",
    "        detections = detect_fn(input_tensor)\n",
    "\n",
    "        bboxes = detections['detection_boxes'][0].numpy()\n",
    "        bclasses = detections['detection_classes'][0].numpy().astype(np.int32)\n",
    "        bscores = detections['detection_scores'][0].numpy()\n",
    "        #det_boxes = ExtractBBoxes(bboxes, bclasses, bscores, im_width, im_height)\n",
    "        #print('bclasses : ', bclasses)\n",
    "        IMAGE_SIZE = (20, 20)\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np1,\n",
    "            np.squeeze(bboxes),\n",
    "            np.squeeze(bclasses).astype(np.int32),\n",
    "            np.squeeze(bscores),\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=4,\n",
    "            min_score_thresh=0.4)\n",
    "        #print('img1 :', img1)\n",
    "        im = Image.fromarray(image_np1)\n",
    "        #img_out = os.path.join('output_1', file.name)\n",
    "        #print('img_out :', img_out)\n",
    "        #cv2.imwrite(img_out, im)\n",
    "        im.save(os.path.join(CWD_PATH, 'output_stop_and_speed_limit',file.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb36791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
